ingress:
  ## name is the name of your ingress file
  name: diem-ingress

  ## tls will be the name of your tls secret. It will be created for you if don't have one
  ## Otherwise get the tls from your cluster
  ## kubectl describe ingress diem-ingress
  ##  TLS: diem-tls-secret terminates example.com
  createtls: true
  tls: diem-tls-secret

  ## host is the hostname of your application
  host: bizops.ibm.com

common:
  config:
    diemAdminRbac: diem-rbac
    diemAdmin: diem-admin
    configmapref: diem-common-config
    K8_SYSTEM_NAME: "Diem on CRC UAT"
    K8_SYSTEM: uat
    K8_INSTANCE: US

  secrets:
    ## secretmapref is the name of the common secret map ref
    secretmapref: diem-common-secret
    SLACKHOOK: ""
    REDIS_URI: ""

## these are the settings for Diem Core
core:

  ## this relates to the diem-core deployment
  deployment:

    ## name is the name of the deployment
    name: diem-core

    ## socketName is the url the client ui socket will connect to
    ## for the moment Do Not Change this
    socketName: etl-socket-server

    tier: backend
    version: 0.1.0
    image: quay.io/diem/core:5.3.0
    replicas: 1
    port: 8080

    ## targetPort is the port diem-core pod will run under
    targetPort: 8192

  config:
    ## configmapref is the name of the common config map ref
    configmapref: diem-core-config

    ## important, the path the application will run under
    APPPATH: /etl-mgr

    spark:
      SPARK_IMAGE: quay.io/diem/pyspark:latest
      SPARK_IMAGEPULLSECRETS: regsecret
      OPERATOR_DRIVER_CORES: "2"
      OPERATOR_DRIVER_MEMORY: 1024m
      OPERATOR_EXECUTOR_CORES: 8
      OPERATOR_EXECUTOR_INSTANCES: 2
      OPERATOR_EXECUTOR_MEMORY: 8G

    volume:
      volumeName: spark-data
      volumeMountPath: /shared
      volumeClaimName: spark-shared-data

    ## Slack integration, enable it by putting the enabled to true
    slack:
      enabled: false
      SLACK_EMOJI: ":diem:"
      SLACK_DEPLOY_CHANNEL: "#diem-deploy-uat"
      SLACK_DEPLOY_USERNAME: "diem- (Notification)"
      SLACK_INTERNAL_CHANNEL: "#diem-bugs-uat"
      SLACK_INTERNAL_USERNAME: "diem - (Internal)"
      SLACK_USER_CHANNEL: "#diem-bugs-uat"
      SLACK_USER_USERNAME: "diem - (User)"

    ## Integrate your own cloud object storage
    ## leave this blank if you want to use minio integrated as a dependency
    ## if these value are going to be used, disable minio
    s3:
      enabled: false
      apiKeyId: ""
      endpoint: ""
      serviceInstanceId: ""

  ## 
  secrets:
    secretmapref: diem-core-secret
    SESSION_NAME: etl.sid
    SESSION_SECRET: ETLSECRETPW
    MONGO_URL: ""
    SENDGRID_API: ""
    JWTTOKEN: ""

  ## OpenId authentication
  auth:
    clientId: ""
    clientSecret: ""
    discoveryUrl: ""
    callbackUrl: sso/callback

nodepy:

  ## configmapref is the name of the nodepy config map ref
  configmapref: diem-nodepy-config
  
  ## image is the the name of the nodepy image 
  image: quay.io/diem/nodepy:latest
  name: nodepy
  port: 8080
  replicas: 1
  targetPort: 8192
  tier: backend
  version: 4.4.1

## enable the spark Operator
## for more details see 
## https://github.com/GoogleCloudPlatform/spark-on-k8s-operator
spark-operator:

  ## overwrite the spark job namespace if needed, otherwise it will
  ## run in the default namespace
  sparkJobNamespace: ""

  ## enables the spark webhoob
  enableWebhook: true
  serviceAccounts:
    spark:
      name: spark
  image:
    repository: quay.io/diem/spark-operator
    tag: 2.0.0

mongodb:
  createservice: true
  auth:
    username: diemadmin
    rootPassword: diemadmin
    password: diempassword
    database: ibmclouddb

redis:
  createservice: true
  password: diempassword

minio:
  createservice: true
  accessKey: diemadmin
  secretKey: diempassword


  persistence:

    ## use an existing claim
    # existingClaim: spark-shared-data
    # VolumeName: spark-data

    ## depending on your capacity you can increase this amount
    size: 20Gi

  mountPath: /minio
  securityContext:
    enabled: false
  resources:
    requests:
      memory: 1Gi
